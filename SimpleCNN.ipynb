{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled24.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPclCCizOb69qkyfUolSF89",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujan123123/NeuralNetworkFromScratch/blob/master/SimpleCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX_aYMPKtwBQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "43e15b76-0633-49b0-944a-78e4c8066ff0"
      },
      "source": [
        "# example of calculation 1d convolutions\n",
        "from numpy import asarray\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D\n",
        "# define input data\n",
        "data = asarray([0, 0, 0, 1, 1, 0, 0, 0])\n",
        "data = data.reshape(1, 8, 1)\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(1, 1, input_shape=(8, 1)))\n",
        "# define a vertical line detector\n",
        "weights = [asarray([[[1]]]), asarray([0.0])]\n",
        "# store the weights in the model\n",
        "model.set_weights(weights)\n",
        "# confirm they were stored\n",
        "print(model.get_weights())\n",
        "# apply filter to input data\n",
        "yhat = model.predict(data)\n",
        "print(yhat)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[[1.]]], dtype=float32), array([0.], dtype=float32)]\n",
            "[[[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [1.]\n",
            "  [1.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s16EY8sEtze1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "81f9abdb-280b-4e42-8af8-3c68b48f8b58"
      },
      "source": [
        "import pickle #saving and loading our serialized model \n",
        "import numpy as np #matrix math\n",
        "from app.model.preprocessor import Preprocessor as img_prep #image preprocessing\n",
        "\n",
        "#class for loading our saved model and classifying new images\n",
        "class LiteOCR:\n",
        "    \n",
        "\tdef __init__(self, fn=\"alpha_weights.pkl\", pool_size=2):\n",
        "        #load the weights from the pickle file and the meta data\n",
        "\t\t[weights, meta] = pickle.load(open(fn, 'rb'), encoding='latin1') #currently, this class MUST be initialized from a pickle file\n",
        "\t\t#list to store labels\n",
        "        self.vocab = meta[\"vocab\"]\n",
        "        \n",
        "        #how many rows and columns in an image\n",
        "\t\tself.img_rows = meta[\"img_side\"] ; self.img_cols = meta[\"img_side\"]\n",
        "        \n",
        "        #load our CNN\n",
        "\t\tself.CNN = LiteCNN()\n",
        "        #with our saved weights\n",
        "\t\tself.CNN.load_weights(weights)\n",
        "        #define the pooling layers size\n",
        "\t\tself.CNN.pool_size=int(pool_size)\n",
        "    \n",
        "    #classify new image\n",
        "\tdef predict(self, image):\n",
        "\t\tprint(image.shape)\n",
        "        #vectorize the image into the right shape for our network\n",
        "\t\tX = np.reshape(image, (1, 1, self.img_rows, self.img_cols))\n",
        "\t\tX = X.astype(\"float32\")\n",
        "        \n",
        "        #make the prediction\n",
        "\t\tpredicted_i = self.CNN.predict(X)\n",
        "        #return the predicted label\n",
        "\t\treturn self.vocab[predicted_i]\n",
        "\n",
        "class LiteCNN:\n",
        "\tdef __init__(self):\n",
        "        # a place to store the layers\n",
        "\t\tself.layers = [] \n",
        "        # size of pooling area for max pooling\n",
        "\t\tself.pool_size = None \n",
        "\n",
        "\tdef load_weights(self, weights):\n",
        "\t\tassert not self.layers, \"Weights can only be loaded once!\"\n",
        "        #add the saved matrix values to the convolutional network\n",
        "\t\tfor k in range(len(weights.keys())):\n",
        "\t\t\tself.layers.append(weights['layer_{}'.format(k)])\n",
        "\n",
        "\tdef predict(self, X):        \n",
        "        #here is where the network magic happens at a high level\n",
        "        h = self.cnn_layer(X, layer_i=0, border_mode=\"full\"); X= h\n",
        "        h = self.relu_layer(X); X = h;\n",
        "        h = self.cnn_layer(X, layer_i=2, border_mode=\"valid\"); X = h\n",
        "        h = self.relu_layer(X); X = h;\n",
        "        h = self.maxpooling_layer(X); X = h\n",
        "        h = self.dropout_layer(X, .25); X = h\n",
        "        h = self.flatten_layer(X, layer_i=7); X = h;\n",
        "        h = self.dense_layer(X, fully, layer_i=10); x = H\n",
        "        h = self.softmax_layer2D(X); x = h\n",
        "        max_i = self.classify(X)\n",
        "        return max_i[0]\n",
        "    \n",
        "    #given our feature map we've learned from convolving around the image\n",
        "    #lets make it more dense by performing pooling, specifically max pooling\n",
        "    #we'll select the max values from the image matrix and use that as our new feature map\n",
        "\tdef maxpooling_layer(self, convolved_features):\n",
        "        #given our learned features and images\n",
        "\t\tnb_features = convolved_features.shape[0]\n",
        "\t\tnb_images = convolved_features.shape[1]\n",
        "\t\tconv_dim = convolved_features.shape[2]\n",
        "\t\tres_dim = int(conv_dim / self.pool_size)       #assumed square shape\n",
        "\n",
        "        #initialize our more dense feature list as empty\n",
        "\t\tpooled_features = np.zeros((nb_features, nb_images, res_dim, res_dim))\n",
        "        #for each image\n",
        "\t\tfor image_i in range(nb_images):\n",
        "            #and each feature map\n",
        "\t\t\tfor feature_i in range(nb_features):\n",
        "                #begin by the row\n",
        "\t\t\t\tfor pool_row in range(res_dim):\n",
        "                    #define start and end points\n",
        "\t\t\t\t\trow_start = pool_row * self.pool_size\n",
        "\t\t\t\t\trow_end   = row_start + self.pool_size\n",
        "\n",
        "                    #for each column (so its a 2D iteration)\n",
        "\t\t\t\t\tfor pool_col in range(res_dim):\n",
        "                        #define start and end points\n",
        "\t\t\t\t\t\tcol_start = pool_col * self.pool_size\n",
        "\t\t\t\t\t\tcol_end   = col_start + self.pool_size\n",
        "                        \n",
        "                        #define a patch given our defined starting ending points\n",
        "\t\t\t\t\t\tpatch = convolved_features[feature_i, image_i, row_start : row_end,col_start : col_end]\n",
        "                        #then take the max value from that patch\n",
        "                        #store it. this is our new learned feature/filter\n",
        "\t\t\t\t\t\tpooled_features[feature_i, image_i, pool_row, pool_col] = np.max(patch)\n",
        "\t\treturn pooled_features\n",
        "\n",
        "    #convolution is the most important of the matrix operations here\n",
        "    #well define our input, lauyer number, and a border mode (explained below)\n",
        "\tdef cnn_layer(self, X, layer_i=0, border_mode = \"full\"):\n",
        "        #we'll store our feature maps and bias value in these 2 vars\n",
        "\t\tfeatures = self.layers[layer_i][\"param_0\"]\n",
        "\t\tbias = self.layers[layer_i][\"param_1\"]\n",
        "        #how big is our filter/patch?\n",
        "\t\tpatch_dim = features[0].shape[-1]\n",
        "        #how many features do we have?\n",
        "\t\tnb_features = features.shape[0]\n",
        "        #How big is our image?\n",
        "\t\timage_dim = X.shape[2] #assume image square\n",
        "        #R G B values\n",
        "\t\timage_channels = X.shape[1]\n",
        "        #how many images do we have?\n",
        "\t\tnb_images = X.shape[0]\n",
        "        \n",
        "        #With border mode \"full\" you get an output that is the \"full\" size as the input. \n",
        "        #That means that the filter has to go outside the bounds of the input by \"filter size / 2\" - \n",
        "        #the area outside of the input is normally padded with zeros.\n",
        "\t\tif border_mode == \"full\":\n",
        "\t\t\tconv_dim = image_dim + patch_dim - 1\n",
        "        #With border mode \"valid\" you get an output that is smaller than the input because \n",
        "        #the convolution is only computed where the input and the filter fully overlap.\n",
        "\t\telif border_mode == \"valid\":\n",
        "\t\t\tconv_dim = image_dim - patch_dim + 1\n",
        "        \n",
        "        #we'll initialize our feature matrix\n",
        "\t\tconvolved_features = np.zeros((nb_images, nb_features, conv_dim, conv_dim));\n",
        "        #then we'll iterate through each image that we have\n",
        "\t\tfor image_i in range(nb_images):\n",
        "            #for each feature \n",
        "\t\t\tfor feature_i in range(nb_features):\n",
        "                #lets initialize a convolved image as empty\n",
        "\t\t\t\tconvolved_image = np.zeros((conv_dim, conv_dim))\n",
        "                #then for each channel (r g b )\n",
        "\t\t\t\tfor channel in range(image_channels):\n",
        "                    #lets extract a feature from our feature map\n",
        "\t\t\t\t\tfeature = features[feature_i, channel, :, :]\n",
        "                    #then define a channel specific part of our image\n",
        "\t\t\t\t\timage   = X[image_i, channel, :, :]\n",
        "                    #perform convolution on our image, using a given feature filter\n",
        "\t\t\t\t\tconvolved_image += self.convolve2d(image, feature, border_mode);\n",
        "\n",
        "                #add a bias to our convoved image\n",
        "\t\t\t\tconvolved_image = convolved_image + bias[feature_i]\n",
        "                #add it to our list of convolved features (learnings)\n",
        "\t\t\t\tconvolved_features[image_i, feature_i, :, :] = convolved_image\n",
        "\t\treturn convolved_features\n",
        "\n",
        "    #In a dense layer, every node in the layer is connected to every node in the preceding layer.\n",
        "\tdef dense_layer(self, X, layer_i=0):\n",
        "        #so we'll initialize our weight and bias for this layer\n",
        "\t\tW = self.layers[layer_i][\"param_0\"]\n",
        "\t\tb = self.layers[layer_i][\"param_1\"]\n",
        "        #and multiply it by our input (dot product)\n",
        "\t\toutput = np.dot(X, W) + b\n",
        "\t\treturn output\n",
        "\n",
        "\t@staticmethod\n",
        "    \n",
        "    #so what does the convolution operation look like?, given an image and a feature map (filter)\n",
        "\tdef convolve2d(image, feature, border_mode=\"full\"):\n",
        "        #we'll define the tensor dimensions of the image and the feature\n",
        "\t\timage_dim = np.array(image.shape)\n",
        "\t\tfeature_dim = np.array(feature.shape)\n",
        "        #as well as a target dimension\n",
        "\t\ttarget_dim = image_dim + feature_dim - 1\n",
        "        #then we'll perform a fast fourier transform on both the input and the filter\n",
        "        #performing a convolution can be written as a for loop but for many convolutions\n",
        "        #this approach is too comp. expensive/slow. it can be performed orders of magnitude\n",
        "        #faster using a fast fourier transform. \n",
        "\t\tfft_result = np.fft.fft2(image, target_dim) * np.fft.fft2(feature, target_dim)\n",
        "        #and set the result to our target \n",
        "\t\ttarget = np.fft.ifft2(fft_result).real\n",
        "\n",
        "\t\tif border_mode == \"valid\":\n",
        "\t\t\t# To compute a valid shape, either np.all(x_shape >= y_shape) or\n",
        "\t\t\t# np.all(y_shape >= x_shape).\n",
        "            #decide a target dimension to convolve around\n",
        "\t\t\tvalid_dim = image_dim - feature_dim + 1\n",
        "\t\t\tif np.any(valid_dim < 1):\n",
        "\t\t\t\tvalid_dim = feature_dim - image_dim + 1\n",
        "\t\t\tstart_i = (target_dim - valid_dim) // 2\n",
        "\t\t\tend_i = start_i + valid_dim\n",
        "\t\t\ttarget = target[start_i[0]:end_i[0], start_i[1]:end_i[1]]\n",
        "\t\treturn target\n",
        "\n",
        "\tdef relu_layer(x):\n",
        "        #turn all negative values in a matrix into zeros\n",
        "\t\tz = np.zeros_like(x)\n",
        "\t\treturn np.where(x>z,x,z)\n",
        "\n",
        "\tdef softmax_layer2D(w):\n",
        "        #this function will calculate the probabilities of each\n",
        "        #target class over all possible target classes. \n",
        "\t\tmaxes = np.amax(w, axis=1)\n",
        "\t\tmaxes = maxes.reshape(maxes.shape[0], 1)\n",
        "\t\te = np.exp(w - maxes)\n",
        "\t\tdist = e / np.sum(e, axis=1, keepdims=True)\n",
        "\t\treturn dist\n",
        "\n",
        "    #affect the probability a node will be turned off by multiplying it\n",
        "    #by a p values (.25 we define)\n",
        "\tdef dropout_layer(X, p):\n",
        "\t\tretain_prob = 1. - p\n",
        "\t\tX *= retain_prob\n",
        "\t\treturn X\n",
        "\n",
        "    #get the largest probabililty value from the list\n",
        "\tdef classify(X):\n",
        "\t\treturn X.argmax(axis=-1)\n",
        "\n",
        "    #tensor transformation, less dimensions\n",
        "\tdef flatten_layer(X):\n",
        "\t\tflatX = np.zeros((X.shape[0],np.prod(X.shape[1:])))\n",
        "\t\tfor i in range(X.shape[0]):\n",
        "\t\t\tflatX[i,:] = X[i].flatten(order='C')\n",
        "\t\treturn flatX"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TabError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-f1750e74258d>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    self.vocab = meta[\"vocab\"]\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mTabError\u001b[0m\u001b[0;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv_avJchvMVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}